{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de gestos de manos \n",
    "\n",
    "- Curso: INFO257 Inteligencia Artificial\n",
    "- Profesor: Pablo Huijse \n",
    "- Consultas por slack o correo: phuijse at inf dot uach dot cl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "El objetivo de esta actividad es entrenar una red convolucional para clasificar gestos de manos \n",
    "\n",
    "Se consideran los siguientes tres gestos\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"img/1.jpg\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"img/2.jpg\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"img/3.jpg\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "1. Un dedo levantado\n",
    "1. Dos dedos levantados\n",
    "1. Tres dedos levantados\n",
    "\n",
    "Más una clase adicional que corresponde a \"fondo vacío\", totalizando cuatro clases a discriminar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "Para resolver esta tarea se le ha proporcionado una base de datos que puede descargar en el siguiente enlace: \n",
    "\n",
    "> https://drive.google.com/file/d/1m9fKMYpUX24sB9PijXq2g54EBxe2W-eO/view?usp=sharing\n",
    "\n",
    "La base de datos ya está separada en conjuntos de entrenamiento, validación y prueba\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones generales\n",
    "\n",
    "- Se trabajará en grupos de dos personas\n",
    "- El grupo debe crear un repositorio privado en www.github.com \n",
    "- Invite a su profesor como colaborador (usuario: phuijse)\n",
    "- No suba los datos al repositorio, suba sólo sus códigos fuente y reportes de resultado\n",
    "- Se evaluará en base al último *commit* del Lunes 10 de Agosto de 2020\n",
    "- Desarrolle en PyTorch\n",
    "- [Sean honestos](https://www.acm.org/about-acm/code-of-ethics-in-spanish)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Instrucciones específicas\n",
    "\n",
    "1. Proponga, entrene y compare distintos modelos de red convolucional para resolver el problema\n",
    "    - Ajuste los parámetros del modelo usando el conjunto de entrenamiento \n",
    "    - Calibre sus hiper-parámetros y prevenga el sobreajuste evaluando en el conjunto de validación \n",
    "    - Compare los modelos finales midiendo su rendimiento en el conjunto de prueba\n",
    "    - Justifique sus decisiones de función de costo, optimizador, arquitectura, regularización, etc.\n",
    "1. Considere al menos dos modelos en su comparación\n",
    "    - Arquitectura convolucional diseñada por usted. Puede partir de una arquitectura existente (e.g. Lenet5) y proponer mejoras de forma iterativa\n",
    "    - Arquitectura ResNet18 pre-entrenada en ImageNet como extractor de características. Diseñe sólo el clasificador final y mantenga el modelo extractor congelado para entrenar\n",
    "1. Presente sus resultados usando matrices de confusión, *accuraccy* y *f1-score*. Considere 5 inicializaciones aleatorias y obtenga barras de error para sus métricas.\n",
    "1. Reporte su proceso, Analice sus resultados, discuta y concluya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageFolder('gestos/train', transform=my_transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "valid_dataset = ImageFolder('gestos/valid', transform=my_transform)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=True, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (mpool): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (activation): ReLU()\n",
       "  (linear1): Linear(in_features=1176, out_features=120, bias=True)\n",
       "  (linear2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (linear3): Linear(in_features=84, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Lenet5(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(type(self), self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(kernel_size=5, in_channels=3, out_channels=12)\n",
    "        self.conv2 = torch.nn.Conv2d(kernel_size=5, in_channels=12, out_channels=24)\n",
    "        self.mpool = torch.nn.MaxPool2d(kernel_size=5)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(in_features=24*7*7, out_features=120)\n",
    "        self.linear2 = torch.nn.Linear(in_features=120, out_features=84)\n",
    "        self.linear3 = torch.nn.Linear(in_features=84, out_features=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.mpool(self.activation(self.conv1(x)))\n",
    "        #print(h.shape)\n",
    "        h = self.mpool(self.activation(self.conv2(h)))\n",
    "        #print(h.shape)\n",
    "        h = h.view(-1, 24*7*7)\n",
    "        h = self.activation(self.linear1(h))\n",
    "        h = self.activation(self.linear2(h))\n",
    "        return self.linear3(h)\n",
    "        \n",
    "    \n",
    "model = Lenet5()\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print metrics so we see some progress\n",
    "        print('\\tTraining batch {} Loss: {:.6f}'.format(batch_idx + 1, loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for data, target in test_loader:\n",
    "            batch_count += 1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss / batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Epoch: 1\n",
      "\tTraining batch 1 Loss: 1.385186\n",
      "\tTraining batch 2 Loss: 1.587036\n",
      "\tTraining batch 3 Loss: 1.407479\n",
      "\tTraining batch 4 Loss: 1.390790\n",
      "\tTraining batch 5 Loss: 1.388707\n",
      "\tTraining batch 6 Loss: 1.635255\n",
      "\tTraining batch 7 Loss: 1.382583\n",
      "\tTraining batch 8 Loss: 1.391438\n",
      "\tTraining batch 9 Loss: 1.386155\n",
      "\tTraining batch 10 Loss: 1.387825\n",
      "\tTraining batch 11 Loss: 1.385450\n",
      "\tTraining batch 12 Loss: 1.384952\n",
      "\tTraining batch 13 Loss: 1.398267\n",
      "\tTraining batch 14 Loss: 1.390164\n",
      "\tTraining batch 15 Loss: 1.385923\n",
      "\tTraining batch 16 Loss: 1.384613\n",
      "\tTraining batch 17 Loss: 1.391155\n",
      "\tTraining batch 18 Loss: 1.389499\n",
      "\tTraining batch 19 Loss: 1.383072\n",
      "\tTraining batch 20 Loss: 1.392362\n",
      "\tTraining batch 21 Loss: 1.390225\n",
      "\tTraining batch 22 Loss: 1.388630\n",
      "\tTraining batch 23 Loss: 1.387901\n",
      "\tTraining batch 24 Loss: 1.386859\n",
      "\tTraining batch 25 Loss: 1.386928\n",
      "\tTraining batch 26 Loss: 1.386109\n",
      "\tTraining batch 27 Loss: 1.386338\n",
      "\tTraining batch 28 Loss: 1.391063\n",
      "\tTraining batch 29 Loss: 1.386258\n",
      "\tTraining batch 30 Loss: 1.388538\n",
      "\tTraining batch 31 Loss: 1.386563\n",
      "\tTraining batch 32 Loss: 1.383984\n",
      "\tTraining batch 33 Loss: 1.380582\n",
      "\tTraining batch 34 Loss: 1.382688\n",
      "\tTraining batch 35 Loss: 1.376398\n",
      "\tTraining batch 36 Loss: 1.374815\n",
      "\tTraining batch 37 Loss: 1.396905\n",
      "\tTraining batch 38 Loss: 1.385993\n",
      "\tTraining batch 39 Loss: 1.400235\n",
      "\tTraining batch 40 Loss: 1.398820\n",
      "\tTraining batch 41 Loss: 1.366990\n",
      "\tTraining batch 42 Loss: 1.382839\n",
      "\tTraining batch 43 Loss: 1.388622\n",
      "\tTraining batch 44 Loss: 1.398768\n",
      "\tTraining batch 45 Loss: 1.419711\n",
      "\tTraining batch 46 Loss: 1.390796\n",
      "\tTraining batch 47 Loss: 1.374898\n",
      "\tTraining batch 48 Loss: 1.353131\n",
      "\tTraining batch 49 Loss: 1.394159\n",
      "\tTraining batch 50 Loss: 1.418233\n",
      "\tTraining batch 51 Loss: 1.367492\n",
      "\tTraining batch 52 Loss: 1.400203\n",
      "\tTraining batch 53 Loss: 1.365870\n",
      "\tTraining batch 54 Loss: 1.392750\n",
      "\tTraining batch 55 Loss: 1.398455\n",
      "\tTraining batch 56 Loss: 1.399285\n",
      "\tTraining batch 57 Loss: 1.416074\n",
      "\tTraining batch 58 Loss: 1.401273\n",
      "\tTraining batch 59 Loss: 1.395932\n",
      "\tTraining batch 60 Loss: 1.395817\n",
      "\tTraining batch 61 Loss: 1.392065\n",
      "\tTraining batch 62 Loss: 1.384937\n",
      "\tTraining batch 63 Loss: 1.387627\n",
      "\tTraining batch 64 Loss: 1.391327\n",
      "\tTraining batch 65 Loss: 1.391220\n",
      "\tTraining batch 66 Loss: 1.384088\n",
      "\tTraining batch 67 Loss: 1.383575\n",
      "\tTraining batch 68 Loss: 1.391016\n",
      "\tTraining batch 69 Loss: 1.384866\n",
      "\tTraining batch 70 Loss: 1.386733\n",
      "\tTraining batch 71 Loss: 1.390925\n",
      "\tTraining batch 72 Loss: 1.388509\n",
      "\tTraining batch 73 Loss: 1.385060\n",
      "\tTraining batch 74 Loss: 1.388777\n",
      "\tTraining batch 75 Loss: 1.384713\n",
      "\tTraining batch 76 Loss: 1.395101\n",
      "\tTraining batch 77 Loss: 1.388351\n",
      "\tTraining batch 78 Loss: 1.386734\n",
      "\tTraining batch 79 Loss: 1.396485\n",
      "\tTraining batch 80 Loss: 1.393138\n",
      "\tTraining batch 81 Loss: 1.386144\n",
      "\tTraining batch 82 Loss: 1.390018\n",
      "\tTraining batch 83 Loss: 1.391521\n",
      "\tTraining batch 84 Loss: 1.379400\n",
      "\tTraining batch 85 Loss: 1.383761\n",
      "\tTraining batch 86 Loss: 1.383386\n",
      "\tTraining batch 87 Loss: 1.379465\n",
      "\tTraining batch 88 Loss: 1.387432\n",
      "\tTraining batch 89 Loss: 1.394657\n",
      "\tTraining batch 90 Loss: 1.379739\n",
      "\tTraining batch 91 Loss: 1.385149\n",
      "\tTraining batch 92 Loss: 1.389647\n",
      "\tTraining batch 93 Loss: 1.382357\n",
      "\tTraining batch 94 Loss: 1.386947\n",
      "\tTraining batch 95 Loss: 1.382873\n",
      "\tTraining batch 96 Loss: 1.395842\n",
      "\tTraining batch 97 Loss: 1.386599\n",
      "\tTraining batch 98 Loss: 1.396986\n",
      "\tTraining batch 99 Loss: 1.377984\n",
      "\tTraining batch 100 Loss: 1.378381\n",
      "\tTraining batch 101 Loss: 1.392493\n",
      "\tTraining batch 102 Loss: 1.387458\n",
      "\tTraining batch 103 Loss: 1.398253\n",
      "\tTraining batch 104 Loss: 1.383054\n",
      "\tTraining batch 105 Loss: 1.390520\n",
      "\tTraining batch 106 Loss: 1.391176\n",
      "\tTraining batch 107 Loss: 1.388043\n",
      "\tTraining batch 108 Loss: 1.373810\n",
      "\tTraining batch 109 Loss: 1.389495\n",
      "\tTraining batch 110 Loss: 1.381663\n",
      "\tTraining batch 111 Loss: 1.381531\n",
      "\tTraining batch 112 Loss: 1.402310\n",
      "\tTraining batch 113 Loss: 1.395164\n",
      "\tTraining batch 114 Loss: 1.385761\n",
      "\tTraining batch 115 Loss: 1.389011\n",
      "\tTraining batch 116 Loss: 1.390048\n",
      "\tTraining batch 117 Loss: 1.380736\n",
      "\tTraining batch 118 Loss: 1.380774\n",
      "\tTraining batch 119 Loss: 1.378647\n",
      "\tTraining batch 120 Loss: 1.388506\n",
      "\tTraining batch 121 Loss: 1.382717\n",
      "\tTraining batch 122 Loss: 1.390740\n",
      "\tTraining batch 123 Loss: 1.385058\n",
      "\tTraining batch 124 Loss: 1.387922\n",
      "\tTraining batch 125 Loss: 1.397779\n",
      "\tTraining batch 126 Loss: 1.381960\n",
      "\tTraining batch 127 Loss: 1.378165\n",
      "\tTraining batch 128 Loss: 1.382380\n",
      "\tTraining batch 129 Loss: 1.386096\n",
      "\tTraining batch 130 Loss: 1.383445\n",
      "\tTraining batch 131 Loss: 1.385245\n",
      "\tTraining batch 132 Loss: 1.390844\n",
      "\tTraining batch 133 Loss: 1.395652\n",
      "\tTraining batch 134 Loss: 1.391565\n",
      "\tTraining batch 135 Loss: 1.382849\n",
      "\tTraining batch 136 Loss: 1.388345\n",
      "\tTraining batch 137 Loss: 1.382281\n",
      "\tTraining batch 138 Loss: 1.397714\n",
      "\tTraining batch 139 Loss: 1.392790\n",
      "\tTraining batch 140 Loss: 1.387603\n",
      "\tTraining batch 141 Loss: 1.392714\n",
      "\tTraining batch 142 Loss: 1.382629\n",
      "\tTraining batch 143 Loss: 1.381338\n",
      "\tTraining batch 144 Loss: 1.391593\n",
      "\tTraining batch 145 Loss: 1.390047\n",
      "\tTraining batch 146 Loss: 1.387254\n",
      "\tTraining batch 147 Loss: 1.393415\n",
      "\tTraining batch 148 Loss: 1.388409\n",
      "\tTraining batch 149 Loss: 1.387247\n",
      "\tTraining batch 150 Loss: 1.388679\n",
      "\tTraining batch 151 Loss: 1.386106\n",
      "\tTraining batch 152 Loss: 1.382009\n",
      "\tTraining batch 153 Loss: 1.389289\n",
      "\tTraining batch 154 Loss: 1.389112\n",
      "\tTraining batch 155 Loss: 1.387200\n",
      "\tTraining batch 156 Loss: 1.386621\n",
      "\tTraining batch 157 Loss: 1.386418\n",
      "\tTraining batch 158 Loss: 1.388257\n",
      "\tTraining batch 159 Loss: 1.372771\n",
      "\tTraining batch 160 Loss: 1.379599\n",
      "\tTraining batch 161 Loss: 1.392204\n",
      "\tTraining batch 162 Loss: 1.395200\n",
      "\tTraining batch 163 Loss: 1.383467\n",
      "\tTraining batch 164 Loss: 1.379068\n",
      "\tTraining batch 165 Loss: 1.388621\n",
      "\tTraining batch 166 Loss: 1.393794\n",
      "\tTraining batch 167 Loss: 1.389957\n",
      "\tTraining batch 168 Loss: 1.379489\n",
      "\tTraining batch 169 Loss: 1.397073\n",
      "\tTraining batch 170 Loss: 1.383565\n",
      "\tTraining batch 171 Loss: 1.393402\n",
      "\tTraining batch 172 Loss: 1.383038\n",
      "\tTraining batch 173 Loss: 1.374374\n",
      "\tTraining batch 174 Loss: 1.398511\n",
      "\tTraining batch 175 Loss: 1.395656\n",
      "\tTraining batch 176 Loss: 1.384602\n",
      "\tTraining batch 177 Loss: 1.388430\n",
      "\tTraining batch 178 Loss: 1.385001\n",
      "\tTraining batch 179 Loss: 1.385104\n",
      "\tTraining batch 180 Loss: 1.385386\n",
      "\tTraining batch 181 Loss: 1.381527\n",
      "\tTraining batch 182 Loss: 1.381850\n",
      "\tTraining batch 183 Loss: 1.396723\n",
      "\tTraining batch 184 Loss: 1.397369\n",
      "\tTraining batch 185 Loss: 1.387589\n",
      "\tTraining batch 186 Loss: 1.396104\n",
      "\tTraining batch 187 Loss: 1.389872\n",
      "\tTraining batch 188 Loss: 1.384675\n",
      "\tTraining batch 189 Loss: 1.380306\n",
      "\tTraining batch 190 Loss: 1.386554\n",
      "\tTraining batch 191 Loss: 1.385187\n",
      "\tTraining batch 192 Loss: 1.391846\n",
      "\tTraining batch 193 Loss: 1.385657\n",
      "\tTraining batch 194 Loss: 1.390563\n",
      "\tTraining batch 195 Loss: 1.386353\n",
      "\tTraining batch 196 Loss: 1.388120\n",
      "\tTraining batch 197 Loss: 1.387316\n",
      "\tTraining batch 198 Loss: 1.381757\n",
      "\tTraining batch 199 Loss: 1.392283\n",
      "\tTraining batch 200 Loss: 1.389469\n",
      "\tTraining batch 201 Loss: 1.390147\n",
      "\tTraining batch 202 Loss: 1.384724\n",
      "\tTraining batch 203 Loss: 1.380930\n",
      "\tTraining batch 204 Loss: 1.388438\n",
      "\tTraining batch 205 Loss: 1.387491\n",
      "\tTraining batch 206 Loss: 1.386319\n",
      "\tTraining batch 207 Loss: 1.387576\n",
      "\tTraining batch 208 Loss: 1.389389\n",
      "\tTraining batch 209 Loss: 1.386534\n",
      "\tTraining batch 210 Loss: 1.386416\n",
      "\tTraining batch 211 Loss: 1.386736\n",
      "\tTraining batch 212 Loss: 1.390584\n",
      "\tTraining batch 213 Loss: 1.386210\n",
      "\tTraining batch 214 Loss: 1.384251\n",
      "\tTraining batch 215 Loss: 1.386257\n",
      "\tTraining batch 216 Loss: 1.388579\n",
      "\tTraining batch 217 Loss: 1.384703\n",
      "\tTraining batch 218 Loss: 1.385354\n",
      "\tTraining batch 219 Loss: 1.387014\n",
      "\tTraining batch 220 Loss: 1.390937\n",
      "\tTraining batch 221 Loss: 1.386774\n",
      "\tTraining batch 222 Loss: 1.390993\n",
      "\tTraining batch 223 Loss: 1.389449\n",
      "\tTraining batch 224 Loss: 1.385468\n",
      "\tTraining batch 225 Loss: 1.387188\n",
      "\tTraining batch 226 Loss: 1.382543\n",
      "\tTraining batch 227 Loss: 1.385155\n",
      "\tTraining batch 228 Loss: 1.384396\n",
      "\tTraining batch 229 Loss: 1.389775\n",
      "\tTraining batch 230 Loss: 1.383556\n",
      "\tTraining batch 231 Loss: 1.387333\n",
      "\tTraining batch 232 Loss: 1.385587\n",
      "\tTraining batch 233 Loss: 1.394477\n",
      "\tTraining batch 234 Loss: 1.382319\n",
      "\tTraining batch 235 Loss: 1.386214\n",
      "\tTraining batch 236 Loss: 1.388012\n",
      "\tTraining batch 237 Loss: 1.379449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining batch 238 Loss: 1.385343\n",
      "\tTraining batch 239 Loss: 1.391157\n",
      "\tTraining batch 240 Loss: 1.388105\n",
      "\tTraining batch 241 Loss: 1.382605\n",
      "\tTraining batch 242 Loss: 1.392217\n",
      "\tTraining batch 243 Loss: 1.377967\n",
      "\tTraining batch 244 Loss: 1.385716\n",
      "\tTraining batch 245 Loss: 1.392067\n",
      "\tTraining batch 246 Loss: 1.380631\n",
      "\tTraining batch 247 Loss: 1.385626\n",
      "\tTraining batch 248 Loss: 1.389735\n",
      "\tTraining batch 249 Loss: 1.400987\n",
      "\tTraining batch 250 Loss: 1.386905\n",
      "\tTraining batch 251 Loss: 1.391507\n",
      "\tTraining batch 252 Loss: 1.389047\n",
      "\tTraining batch 253 Loss: 1.387166\n",
      "\tTraining batch 254 Loss: 1.395116\n",
      "\tTraining batch 255 Loss: 1.389122\n",
      "\tTraining batch 256 Loss: 1.392132\n",
      "\tTraining batch 257 Loss: 1.383572\n",
      "\tTraining batch 258 Loss: 1.387740\n",
      "\tTraining batch 259 Loss: 1.387536\n",
      "\tTraining batch 260 Loss: 1.379780\n",
      "\tTraining batch 261 Loss: 1.388891\n",
      "\tTraining batch 262 Loss: 1.386151\n",
      "\tTraining batch 263 Loss: 1.384807\n",
      "\tTraining batch 264 Loss: 1.387876\n",
      "\tTraining batch 265 Loss: 1.387126\n",
      "\tTraining batch 266 Loss: 1.384740\n",
      "\tTraining batch 267 Loss: 1.385603\n",
      "\tTraining batch 268 Loss: 1.389090\n",
      "\tTraining batch 269 Loss: 1.376268\n",
      "\tTraining batch 270 Loss: 1.381947\n",
      "\tTraining batch 271 Loss: 1.388943\n",
      "\tTraining batch 272 Loss: 1.385849\n",
      "\tTraining batch 273 Loss: 1.384983\n",
      "\tTraining batch 274 Loss: 1.388835\n",
      "\tTraining batch 275 Loss: 1.398738\n",
      "\tTraining batch 276 Loss: 1.389255\n",
      "\tTraining batch 277 Loss: 1.394659\n",
      "\tTraining batch 278 Loss: 1.386396\n",
      "\tTraining batch 279 Loss: 1.384079\n",
      "\tTraining batch 280 Loss: 1.393605\n",
      "\tTraining batch 281 Loss: 1.388007\n",
      "\tTraining batch 282 Loss: 1.387858\n",
      "\tTraining batch 283 Loss: 1.391643\n",
      "\tTraining batch 284 Loss: 1.389898\n",
      "\tTraining batch 285 Loss: 1.381927\n",
      "\tTraining batch 286 Loss: 1.381961\n",
      "\tTraining batch 287 Loss: 1.388822\n",
      "\tTraining batch 288 Loss: 1.375685\n",
      "\tTraining batch 289 Loss: 1.385402\n",
      "\tTraining batch 290 Loss: 1.388892\n",
      "\tTraining batch 291 Loss: 1.388177\n",
      "\tTraining batch 292 Loss: 1.387412\n",
      "\tTraining batch 293 Loss: 1.384122\n",
      "\tTraining batch 294 Loss: 1.388122\n",
      "\tTraining batch 295 Loss: 1.381978\n",
      "\tTraining batch 296 Loss: 1.389086\n",
      "\tTraining batch 297 Loss: 1.391094\n",
      "\tTraining batch 298 Loss: 1.388117\n",
      "\tTraining batch 299 Loss: 1.390641\n",
      "\tTraining batch 300 Loss: 1.387035\n",
      "\tTraining batch 301 Loss: 1.383465\n",
      "\tTraining batch 302 Loss: 1.389410\n",
      "\tTraining batch 303 Loss: 1.385293\n",
      "\tTraining batch 304 Loss: 1.395507\n",
      "\tTraining batch 305 Loss: 1.392211\n",
      "\tTraining batch 306 Loss: 1.395432\n",
      "\tTraining batch 307 Loss: 1.391199\n",
      "\tTraining batch 308 Loss: 1.389248\n",
      "\tTraining batch 309 Loss: 1.385592\n",
      "\tTraining batch 310 Loss: 1.383505\n",
      "\tTraining batch 311 Loss: 1.386852\n",
      "\tTraining batch 312 Loss: 1.387755\n",
      "\tTraining batch 313 Loss: 1.387133\n",
      "Training set: Average loss: 1.389142\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3684e38a4090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mepoch_nums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtraining_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "\n",
    "model = Lenet5()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "max_epochs = 100  \n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "def train_one_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    yhat = model.forward(x)\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item() # Este output puede llamar luego como trainer.state.output\n",
    "\n",
    "# Esto es lo que hace el engine de evaluación\n",
    "def evaluate_one_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yhat = model.forward(x)\n",
    "        #loss = criterion(yhat, y)\n",
    "        return yhat, y\n",
    "\n",
    "    \n",
    "trainer = Engine(train_one_step)\n",
    "evaluator = Engine(evaluate_one_step)\n",
    "metrics = {'Loss': Loss(criterion), 'Acc': Accuracy()}\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(evaluator, name)# Use an \"Adam\" optimizer to adjust weights\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "# Train over 10 epochs (We restrict to 10 for time issues)\n",
    "epochs = 10\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
