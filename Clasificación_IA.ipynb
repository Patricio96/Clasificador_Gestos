{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clasificación_IA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7af43050688b4189bbb3f0123db245fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9aee27bd6bb740eaa9b3357a77980a26",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_543c8ac85a25477faba2ecceaa8f233e",
              "IPY_MODEL_c60b2f00ae8d411f80b62b576a26ed51"
            ]
          }
        },
        "9aee27bd6bb740eaa9b3357a77980a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "543c8ac85a25477faba2ecceaa8f233e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b34f56b4ef24634a6ca9a88d9004a10",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a921780fcb047d5b5c2bf55efb3e629"
          }
        },
        "c60b2f00ae8d411f80b62b576a26ed51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7302e716ea4544b88b43f9631e54fb22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [00:04&lt;00:00, 51.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b5f8caaf1214936a2a2ea6771d89f57"
          }
        },
        "8b34f56b4ef24634a6ca9a88d9004a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a921780fcb047d5b5c2bf55efb3e629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7302e716ea4544b88b43f9631e54fb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b5f8caaf1214936a2a2ea6771d89f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8332fdd552d74d74a5746ac4dad633e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_910bf0cc9192482193401d457f92c5d7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4fd2e5b870d440aa4412721526e061e",
              "IPY_MODEL_3b584cce29a14f7e850f3a372e981fde"
            ]
          }
        },
        "910bf0cc9192482193401d457f92c5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4fd2e5b870d440aa4412721526e061e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd1d87de69d44d2a8608100641ce7629",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14212972,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14212972,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7956b6fb74cd4ead8f9481c9c8736eac"
          }
        },
        "3b584cce29a14f7e850f3a372e981fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39700b876cfc4708b4d093ba56470230",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13.6M/13.6M [00:00&lt;00:00, 27.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a958e1e05794309be0da22473cfb134"
          }
        },
        "fd1d87de69d44d2a8608100641ce7629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7956b6fb74cd4ead8f9481c9c8736eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39700b876cfc4708b4d093ba56470230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a958e1e05794309be0da22473cfb134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e0cf23203e24cee8febb7fb8d291e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7beed8c0e15459a855afb0e48c282cb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d70b940faa74517aca8a3e84a216224",
              "IPY_MODEL_826e6dab360d41da8486b04960f4cbc5"
            ]
          }
        },
        "c7beed8c0e15459a855afb0e48c282cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d70b940faa74517aca8a3e84a216224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b1cd7fb6b7f4ee19e5cbbd8f98100c9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 52147035,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52147035,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a32261591ff4911b81dd0c219572e9d"
          }
        },
        "826e6dab360d41da8486b04960f4cbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31c44f5194f847bea33f93af21b4db22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49.7M/49.7M [00:01&lt;00:00, 38.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62d73a65db344eaaa726fdc59c95ab76"
          }
        },
        "9b1cd7fb6b7f4ee19e5cbbd8f98100c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a32261591ff4911b81dd0c219572e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31c44f5194f847bea33f93af21b4db22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62d73a65db344eaaa726fdc59c95ab76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA30PQytIx0d",
        "colab_type": "text"
      },
      "source": [
        "# **Trabajo unidad 4: Clasificación de gestos de manos**\n",
        "# INFO257 Inteligencia Artificial\n",
        "\n",
        "**Integrantes**: *Patricio Canales*, *Eleazar Vásquez*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgqSwtufJESu",
        "colab_type": "text"
      },
      "source": [
        "# **Descarga del dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIDWQnNB2EpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d819a9b3-615c-4d10-9635-6b175ec71080"
      },
      "source": [
        "!gdown \"https://drive.google.com/u/0/uc?export=download&confirm=trOT&id=1m9fKMYpUX24sB9PijXq2g54EBxe2W-eO\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?export=download&confirm=trOT&id=1m9fKMYpUX24sB9PijXq2g54EBxe2W-eO\n",
            "To: /content/gestos.zip\n",
            "148MB [00:01, 85.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh29b7IxGU5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q gestos.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTTD_2DRGZ99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms \n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torchvision import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_XVEHnnGf3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "289599e1-4bdd-4c53-84cc-746171cbde45"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  display(torch.cuda.get_device_name(0))\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_do5pPnJLE5",
        "colab_type": "text"
      },
      "source": [
        "# **Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LVaCmp4Gjh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "train_dataset = ImageFolder('gestos/train', transform=train_transforms)\n",
        "valid_dataset = ImageFolder('gestos/valid', transform=valid_transforms)\n",
        "test_dataset = ImageFolder('gestos/test', transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
        "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=128)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=256)\n",
        "\n",
        "dataloaders_dict = {\"train\": train_loader, \"valid\": valid_loader}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySQSWXcyJMhh",
        "colab_type": "text"
      },
      "source": [
        "# **Consideraciones para la carga del dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL0afnngJTPn",
        "colab_type": "text"
      },
      "source": [
        "*   Como las imágenes son de tamaño 200x200, hacemos un Resize para agrandar la imagen (los modelos pre-entrenados esperan una imagen de tamaño al menos 224x224).\n",
        "*   Al conjunto de datos de entrenamiento es necesario darle un shuffle = True, ya que asi los datos los procesa de manera aleatoria en cada época.\n",
        "* El tamaño del batch de entrenamiento tiene que ser bajo, para que el modelo tome en cada época pequeñas muestras de todo el conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIc3NpR6KEmQ",
        "colab_type": "text"
      },
      "source": [
        "# **Entrenamiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C_hhJSpKGH4",
        "colab_type": "text"
      },
      "source": [
        "- Para el entrenamiento de nuestro modelos, utilizamos la funcion **train_model()** la cual recibe los parametro necesario para el entrenamiento. \n",
        "\n",
        "- Esta función internamente guarda en el directorio el mejor modelo de entrenamiento en base a la metrica **loss_valid**, dentro del ciclo de las épocas, así evitamos el sobre ajuste ya que nos quedamos con el mejor modelo entrenado y no con el último.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbLSZ98NGpZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs,best_model):\n",
        "  best_valid_loss = np.inf\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      for x, y in train_loader:\n",
        "          x=x.to(device)\n",
        "          y=y.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          yhat = model.forward(x)\n",
        "          loss = criterion(yhat, y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      epoch_loss = 0.0\n",
        "      model.eval()\n",
        "      for x, y in valid_loader:\n",
        "          x=x.to(device)\n",
        "          y=y.to(device)\n",
        "          yhat = model.forward(x)\n",
        "          loss = criterion(yhat, y)\n",
        "          epoch_loss += loss.item()\n",
        "      if (epoch_loss < best_valid_loss):\n",
        "        best_valid_loss = epoch_loss\n",
        "        torch.save({'current_epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'current_valid_loss': epoch_loss\n",
        "                   }, best_model)\n",
        "        print(\"guardando..\")\n",
        "      print(epoch, epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXmyiFidKNwp",
        "colab_type": "text"
      },
      "source": [
        "# **Calculo de rendimiento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iimPl2V6GsQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(model):\n",
        "  targets, predictions = [], []\n",
        "  for mbdata, label in test_loader:\n",
        "      mbdata, label = mbdata.to(device), label.to(device)\n",
        "      logits = model.forward(mbdata)\n",
        "      predictions.append(logits.argmax(dim=1).detach().cpu().numpy())     \n",
        "      targets.append(label.cpu().numpy()) \n",
        "  predictions = np.concatenate(predictions) \n",
        "  targets = np.concatenate(targets)\n",
        "\n",
        "  from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "  cm = confusion_matrix(targets, predictions)\n",
        "  display(cm)\n",
        "  print(classification_report(targets, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPAQKSzlKSFy",
        "colab_type": "text"
      },
      "source": [
        "# **Modelos pre-entrenados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjWBH51MKSyQ",
        "colab_type": "text"
      },
      "source": [
        "A continuación usaremos modelos que nos provee [`torchvision.models`](https://pytorch.org/docs/stable/torchvision/models.html) para clasificar un conjunto de fotos en 0 dedos levantados, 1, 2, o 3. El proceso es el siguiente, primero se carga cada modelo, luego re-entrenaremos la última capa del modelo (en algunos casos puede ser más), para finalmente realizar las predicciones con el conjunto de datos de prueba, mostrando matrices de confusión, accuraccy y f1-score. Hay que tener en cuenta que cada modelo posee ciertos parámetros diferentes como la función de pérdida, el optimizador o el número de épocas, son esos parámetros los cuales podemos modificar para encontrar el adecuado en cada modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWhBzAXlKV6d",
        "colab_type": "text"
      },
      "source": [
        "# **Modelo ResNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udSynkmIGue7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = models.resnet18(pretrained=True, progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9E6j0apGwcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Congelamos todos los parámetros\n",
        "for param in resnet.parameters(): \n",
        "    param.requires_grad = False\n",
        "\n",
        "neuronsResnet = resnet.fc.in_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmG2HECTGzRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet.fc = torch.nn.Sequential(\n",
        "                                  torch.nn.Linear(in_features=neuronsResnet, out_features=256, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True), \n",
        "                                  torch.nn.Linear(in_features=256, out_features=128, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),\n",
        "                                  torch.nn.Linear(in_features=128, out_features=4, bias=True))\n",
        "\n",
        "resnet.to(device)\n",
        "\n",
        "criterionResnet = torch.nn.CrossEntropyLoss()\n",
        "optimizerResnet = torch.optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
        "criterionResnet.to(device)\n",
        "br = 'best_resnet.pt'\n",
        "\n",
        "nEpochResnet = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsZ7uqgUN0uy",
        "colab_type": "text"
      },
      "source": [
        "**Entrenamiento del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxPWyJGXG3Fs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "11bda2f0-5267-4da9-9f9c-4fe99445875b"
      },
      "source": [
        "resnet.to(device)\n",
        "train_model(resnet, criterionResnet, optimizerResnet, nEpochResnet,br)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "guardando..\n",
            "0 3.5243545286357403\n",
            "guardando..\n",
            "1 1.8489606939256191\n",
            "guardando..\n",
            "2 1.137607254087925\n",
            "guardando..\n",
            "3 0.8255511485040188\n",
            "guardando..\n",
            "4 0.6979451049119234\n",
            "5 1.0714541701599956\n",
            "6 0.7231131545267999\n",
            "7 0.8753209854476154\n",
            "8 0.8094796063378453\n",
            "guardando..\n",
            "9 0.6845975248143077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYxamhliL0dA",
        "colab_type": "text"
      },
      "source": [
        "**Recuperando el mejor modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwFgeHRQIZLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78e5f02e-2152-4c35-e28e-51b2b27e2b0f"
      },
      "source": [
        "resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "resnet.fc = torch.nn.Sequential(\n",
        "                                  torch.nn.Linear(in_features=neuronsResnet, out_features=256, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),\n",
        "                                  torch.nn.Linear(in_features=256, out_features=128, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),  \n",
        "                                  torch.nn.Linear(in_features=128, out_features=4, bias=True))\n",
        "resnet.to(device)\n",
        "resnet.load_state_dict(torch.load('best_resnet.pt')['model_state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Emstd0MB3_",
        "colab_type": "text"
      },
      "source": [
        "**Matriz de confusión y reporte de clasificación**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia3qW4NkIe3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6109361d-b186-4442-b9f7-68cdaadce1e5"
      },
      "source": [
        "resnet.to(device)\n",
        "testing(resnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[29,  0,  1,  0],\n",
              "       [ 0, 30,  0,  0],\n",
              "       [ 0,  0, 24,  6],\n",
              "       [ 0,  0,  2, 28]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        30\n",
            "           1       1.00      1.00      1.00        30\n",
            "           2       0.89      0.80      0.84        30\n",
            "           3       0.82      0.93      0.87        30\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.93      0.93       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A9gI73cMrSk",
        "colab_type": "text"
      },
      "source": [
        "# **Observaciones de modelo resnet18**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwJp-1xlMsJU",
        "colab_type": "text"
      },
      "source": [
        "*   Inicialmente usamos el optimizador Adam que nos proporciona torch.optim,obteniendo resultados relativamente malos (entre 0.50 y 0.70 en f1-score), cambiamos varias veces la tasa de aprendizaje, pero aun asi cambiaba poco los resultados, seguramente porque este tipo de red es muy grande y Adam va mejor en modelos que sean mas rápidos. Por este motivo cambiamos al optimizador SGD lo cual mejoró consireblemente los resultados como se ve en la última matriz de confusión.\n",
        "\n",
        "*   Para la función de pérdida usamos la CrossEntropyLoss que une nn.LogSoftmax() y nn.NLLLoss() de torch, la cual es útil cuando se entrena un problema de clasificación como es en este caso.\n",
        "\n",
        "* En cuanto a la arquitectura de la última capa, agregamos 2 capas extras y cada una con una función de activación Relu para disminuir el error provocado en cada capa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmaFg3JRNBTx",
        "colab_type": "text"
      },
      "source": [
        "# **Modelo AlexNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L78vQc52NEBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "7af43050688b4189bbb3f0123db245fd",
            "9aee27bd6bb740eaa9b3357a77980a26",
            "543c8ac85a25477faba2ecceaa8f233e",
            "c60b2f00ae8d411f80b62b576a26ed51",
            "8b34f56b4ef24634a6ca9a88d9004a10",
            "4a921780fcb047d5b5c2bf55efb3e629",
            "7302e716ea4544b88b43f9631e54fb22",
            "2b5f8caaf1214936a2a2ea6771d89f57"
          ]
        },
        "outputId": "0a750158-edf1-46bb-b9a5-e0bb92c18a74"
      },
      "source": [
        "alexnet = models.alexnet(pretrained=True, progress=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7af43050688b4189bbb3f0123db245fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZlhONhqNLYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in alexnet.parameters(): \n",
        "    param.requires_grad = False\n",
        "\n",
        "alexnet.classifier = torch.nn.Sequential(torch.nn.Linear(9216, out_features=4000, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),\n",
        "                                  torch.nn.Linear(in_features=4000, out_features=1000, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True), \n",
        "                                  torch.nn.Linear(in_features=1000, out_features=4, bias=True))\n",
        "alexnet.to(device)\n",
        "\n",
        "criterionAlexNet = torch.nn.CrossEntropyLoss()\n",
        "optimizerAlexNet = torch.optim.Adam(alexnet.parameters(), lr=0.0001)\n",
        "criterionAlexNet.to(device)\n",
        "\n",
        "nEpochAlexNet = 10\n",
        "ba = 'best_alexnet.pt'\n",
        "#display(alexnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbqAHNxVNiyF",
        "colab_type": "text"
      },
      "source": [
        "**Entrenamiento del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZia2WNiNmMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "8e5dcaec-271b-432e-8da2-a477486d497a"
      },
      "source": [
        "alexnet.to(device)\n",
        "train_model(alexnet, criterionAlexNet, optimizerAlexNet, nEpochAlexNet, ba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "guardando..\n",
            "0 11.780551041179024\n",
            "guardando..\n",
            "1 5.116900558542284\n",
            "guardando..\n",
            "2 4.207319953700534\n",
            "guardando..\n",
            "3 3.9937539512333657\n",
            "guardando..\n",
            "4 3.7068496449045334\n",
            "guardando..\n",
            "5 3.7047911156503797\n",
            "guardando..\n",
            "6 3.589061785658579\n",
            "guardando..\n",
            "7 3.5816695839970194\n",
            "8 3.60148520372233\n",
            "9 3.5840233730132436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1IATZdkSNFC",
        "colab_type": "text"
      },
      "source": [
        "**Recuperando el mejor modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnBkQ8VxRvzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "5e1a1779-d5a9-45c0-d5de-0daf042db750"
      },
      "source": [
        "best_alexnet = models.alexnet()\n",
        "\n",
        "best_alexnet.classifier = torch.nn.Sequential(torch.nn.Linear(9216, out_features=4000, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),  \n",
        "                                  torch.nn.Linear(in_features=4000, out_features=1000, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),  \n",
        "                                  torch.nn.Linear(in_features=1000, out_features=4, bias=True))\n",
        "best_alexnet.load_state_dict(torch.load('best_alexnet.pt')['model_state_dict'])\n",
        "best_alexnet.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=9216, out_features=4000, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=4000, out_features=1000, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=1000, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWuinrIRPc9M",
        "colab_type": "text"
      },
      "source": [
        "**Matriz de confusión y reporte de clasificación**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upx64EhZPIx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "75ac8121-4f07-4d36-c593-98f245404da6"
      },
      "source": [
        "best_alexnet.to(device)\n",
        "testing(alexnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[14,  5,  2,  9],\n",
              "       [ 0, 17,  3, 10],\n",
              "       [ 0,  0, 21,  9],\n",
              "       [ 0,  2,  5, 23]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.47      0.64        30\n",
            "           1       0.71      0.57      0.63        30\n",
            "           2       0.68      0.70      0.69        30\n",
            "           3       0.45      0.77      0.57        30\n",
            "\n",
            "    accuracy                           0.62       120\n",
            "   macro avg       0.71      0.62      0.63       120\n",
            "weighted avg       0.71      0.62      0.63       120\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSn9Q3dVPkly",
        "colab_type": "text"
      },
      "source": [
        "# **Observaciones modelo AlexNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-rnPfNyPldx",
        "colab_type": "text"
      },
      "source": [
        "* La arquitectura de este modelo es similar a la Lenet5, pero con\n",
        "mas filtros por capa y mas profunda. A la última capa le agreamos 2 capas adicionales que soportan una mayor cantidad de neuronas que la Lenet, para que la red sea mas compleja y cada una con una función de activación Relu para disminuir el error en cada capa.\n",
        "\n",
        "* Para la función de pérdida usamos la misma que en el modelo anterior la CrossEntropyLoss, ya que es la que mejor funciona con problemas de clasificación.\n",
        "\n",
        "* El optimizador en este caso usamos Adam con una tasa de aprendizaje de 0.0001 ya que en este caso posee menos capas ocultas en comparacion a la resnet y nos daba mejores resultados que el optimizador SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU1_mWN_PvNh",
        "colab_type": "text"
      },
      "source": [
        "# **Modelo MobileNet v2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjOVvtclPw0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "8332fdd552d74d74a5746ac4dad633e4",
            "910bf0cc9192482193401d457f92c5d7",
            "d4fd2e5b870d440aa4412721526e061e",
            "3b584cce29a14f7e850f3a372e981fde",
            "fd1d87de69d44d2a8608100641ce7629",
            "7956b6fb74cd4ead8f9481c9c8736eac",
            "39700b876cfc4708b4d093ba56470230",
            "5a958e1e05794309be0da22473cfb134"
          ]
        },
        "outputId": "ce539beb-8a2c-4a49-a930-7ed6462b5438"
      },
      "source": [
        "mobilenet = models.mobilenet_v2(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8332fdd552d74d74a5746ac4dad633e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14212972.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kYbrCdQP60a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in mobilenet.parameters(): \n",
        "    param.requires_grad = False\n",
        "\n",
        "mobilenet.classifier = torch.nn.Sequential(torch.nn.Linear(1280, out_features=600, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),\n",
        "                                  torch.nn.Linear(in_features=600, out_features=100, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),\n",
        "                                  torch.nn.Linear(in_features=100, out_features=4, bias=True))\n",
        "mobilenet.to(device)\n",
        "\n",
        "criterionMobileNet = torch.nn.CrossEntropyLoss()\n",
        "optimizerMobileNet = torch.optim.Adam(mobilenet.parameters(), lr=1e-3)\n",
        "criterionMobileNet.to(device)\n",
        "\n",
        "nEpochMobileNet = 10\n",
        "bm = 'best_mobilenet.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XmmJ30XP-GU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "3c88390f-f972-4bef-f45d-5075491f24fd"
      },
      "source": [
        "mobilenet.to(device)\n",
        "train_model(mobilenet, criterionMobileNet, optimizerMobileNet, nEpochMobileNet, bm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "guardando..\n",
            "0 23.166823682375252\n",
            "guardando..\n",
            "1 20.45856876628818\n",
            "2 30.907916438505254\n",
            "3 35.13937383352095\n",
            "4 62.415424939899985\n",
            "5 27.91690421430419\n",
            "6 73.26077154718949\n",
            "7 37.166377453580594\n",
            "8 49.56716681255145\n",
            "9 68.83380017747083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TSys0RqSQiF",
        "colab_type": "text"
      },
      "source": [
        "**Recuperando el mejor modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7ZaYazdSRMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3937462c-3ed3-4e49-fc7f-90adbea8e878"
      },
      "source": [
        "best_mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "best_mobilenet.classifier = torch.nn.Sequential(torch.nn.Linear(1280, out_features=600, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),\n",
        "                                  torch.nn.Linear(in_features=600, out_features=100, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),  \n",
        "                                  torch.nn.Linear(in_features=100, out_features=4, bias=True))\n",
        "best_mobilenet.load_state_dict(torch.load('best_mobilenet.pt')['model_state_dict'])\n",
        "best_mobilenet.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNReLU(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvBNReLU(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1280, out_features=600, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=600, out_features=100, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=100, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl2Qh_-DWF1n",
        "colab_type": "text"
      },
      "source": [
        "**Matriz de confusión y reporte de clasificación**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpYZBRJSSWGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "007578ed-ca88-4e66-ea01-1c2499d8cfcf"
      },
      "source": [
        "best_mobilenet.to(device)\n",
        "testing(best_mobilenet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[18,  4,  1,  7],\n",
              "       [ 0, 22,  2,  6],\n",
              "       [ 0,  7, 15,  8],\n",
              "       [ 0,  3,  4, 23]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75        30\n",
            "           1       0.61      0.73      0.67        30\n",
            "           2       0.68      0.50      0.58        30\n",
            "           3       0.52      0.77      0.62        30\n",
            "\n",
            "    accuracy                           0.65       120\n",
            "   macro avg       0.70      0.65      0.65       120\n",
            "weighted avg       0.70      0.65      0.65       120\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpPpCNR3S55-",
        "colab_type": "text"
      },
      "source": [
        "# **Observaciones MobileNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRW66ApqS-gn",
        "colab_type": "text"
      },
      "source": [
        " * MobileNet v2 utiliza convoluciones ligeras en profundidad para filtrar\n",
        " entidades en la capa de expansión intermedia. Además, se eliminaron\n",
        " las no linealidades en las capas estrechas para mantener la potencia\n",
        " de representación. A la última capa le agregamos 2 cada una con \n",
        "una función de activación Relu.\n",
        "\n",
        "* Para la función de pérdida usamo la CrossEntropyLoss siguiendo \n",
        "las mismas consideraciones que en los modelos anteriores\n",
        "\n",
        "* El optimizador que elegimos al final fue Adam ya que era el que \n",
        "mejor resultados nos daba, teniendo una tasa de aprendizaje de 0.001. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5G33ePWTU9N",
        "colab_type": "text"
      },
      "source": [
        "# **Modelo GoogleNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY4HgT_HTYNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "2e0cf23203e24cee8febb7fb8d291e5b",
            "c7beed8c0e15459a855afb0e48c282cb",
            "2d70b940faa74517aca8a3e84a216224",
            "826e6dab360d41da8486b04960f4cbc5",
            "9b1cd7fb6b7f4ee19e5cbbd8f98100c9",
            "8a32261591ff4911b81dd0c219572e9d",
            "31c44f5194f847bea33f93af21b4db22",
            "62d73a65db344eaaa726fdc59c95ab76"
          ]
        },
        "outputId": "c1b57e08-2d9b-4b90-eafb-9ddfa8f93af0"
      },
      "source": [
        "googlenet = models.googlenet(pretrained=True, progress=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e0cf23203e24cee8febb7fb8d291e5b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=52147035.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDjo3axMTcH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in googlenet.parameters(): \n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIV7tGdQThnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "googlenet.fc = torch.nn.Sequential(torch.nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),\n",
        "                                  torch.nn.Linear(in_features=512, out_features=4, bias=True))\n",
        "\n",
        "googlenet.to(device)\n",
        "\n",
        "criterionGoogleNet = torch.nn.CrossEntropyLoss()\n",
        "optimizerGoogleNet = torch.optim.SGD(googlenet.parameters(), lr=0.001, momentum=0.9)\n",
        "criterionGoogleNet.to(device)  \n",
        "\n",
        "nEpochGoogleNet = 10\n",
        "bg = 'best_googlenet.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o3B7QNSTpG1",
        "colab_type": "text"
      },
      "source": [
        "**Entrenamiento del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCu91qfsTqP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ab15d64d-3133-4566-9d44-a317e465e36b"
      },
      "source": [
        "googlenet.to(device)\n",
        "train_model(googlenet, criterionGoogleNet, optimizerGoogleNet, nEpochGoogleNet, bg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "guardando..\n",
            "0 10.634019777178764\n",
            "guardando..\n",
            "1 7.710035875439644\n",
            "guardando..\n",
            "2 5.86761874333024\n",
            "guardando..\n",
            "3 5.833686497062445\n",
            "guardando..\n",
            "4 4.690093219280243\n",
            "5 5.087892876937985\n",
            "guardando..\n",
            "6 4.404778080061078\n",
            "7 4.907697562128305\n",
            "8 5.154789896681905\n",
            "9 4.941428128629923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuAx1Qo9YwAF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P79vIxvYVpnU",
        "colab_type": "text"
      },
      "source": [
        "**Recuperando el mejor modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptokgpj6VovO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a505033-c1f3-4f2c-b72b-2bf33ddd45e6"
      },
      "source": [
        "best_googlenet = models.googlenet(pretrained=True)\n",
        "best_googlenet.fc = torch.nn.Sequential(torch.nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "                                  torch.nn.ReLU(inplace=True),\n",
        "                                  torch.nn.Linear(in_features=512, out_features=4, bias=True))\n",
        "\n",
        "best_googlenet.load_state_dict(torch.load('best_googlenet.pt')['model_state_dict'])\n",
        "best_googlenet.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (conv1): BasicConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2): BasicConv2d(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv3): BasicConv2d(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception3a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception3b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception4a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4c): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4d): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4e): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception5a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception5b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (aux1): None\n",
              "  (aux2): None\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=512, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZL8931iV6OP",
        "colab_type": "text"
      },
      "source": [
        "**Matriz de confusión y reporte de clasificación**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9NyVcRcV7Lt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b33c38e5-92dc-46ec-c6ca-244877adeb96"
      },
      "source": [
        "best_googlenet.to(device)\n",
        "testing(best_googlenet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[25,  1,  1,  3],\n",
              "       [ 1, 19,  2,  8],\n",
              "       [ 0,  6, 18,  6],\n",
              "       [ 0,  1,  6, 23]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.83      0.89        30\n",
            "           1       0.70      0.63      0.67        30\n",
            "           2       0.67      0.60      0.63        30\n",
            "           3       0.57      0.77      0.66        30\n",
            "\n",
            "    accuracy                           0.71       120\n",
            "   macro avg       0.73      0.71      0.71       120\n",
            "weighted avg       0.73      0.71      0.71       120\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3YJqwkgcg6C",
        "colab_type": "text"
      },
      "source": [
        "# **Observaciones GoogleNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWQBvmv7eDCp",
        "colab_type": "text"
      },
      "source": [
        "* GoogLeNet se basó en una arquitectura de red neuronal convolucional profunda con el nombre en código \"Inception\", que era responsable de establecer el nuevo estado de la técnica para la clasificación y detección en el ImageNet Large-Scale Visual Recognition Challenge 2014. Este modelo pre-entrenado que tiene una arquitectura bastante compleja, decidimos agregar una capa Linear conectada a la ultima caoa de salida, de acuerdo a nuestro problema propio.\n",
        "\n",
        "* En cuanto a la función de perdida, decidimos utilizar CrossEntropyLoss siguiendo las mismas consideraciones que los modelos.\n",
        "\n",
        "* Para el optimizador cambiamos de Adam a SGD, ya que funciona mejor con redes mas complejas y grandes como es en este caso, pero al probar con ambos optimizadores, los resultados eran bastante similares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-p5ErJl8WyA",
        "colab_type": "text"
      },
      "source": [
        "# **Conclusiones Generales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYq6hVcn8dO3",
        "colab_type": "text"
      },
      "source": [
        "Nos dimos cuenta que cada modelo funciona diferente, y los hiper-parámetreos que uno modifica, no son siempre los mismos valores. Para cada problema pueden variar estos parámetros, y por eso es sumamente necesario saber como funcionan los modelos y a que corresponde cada parámetro. En este caso, los mejores resultados los obtuvimos con el modelo resnet18, que en comparación a los otros 3 modelos sus resultados vistos en la matriz de confusión son mejores, mas precisas y con un mejor recall. La razón de estos resultados puede deberse a que el modelo resnet es uno de los más recientes y por lo tanto tiene mejoras en su algoritmo de redes neuronales que otros modelos mas antiguos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_FEOwm-_-am",
        "colab_type": "text"
      },
      "source": [
        "# **Resnet18 vs Lenet5 modificada**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KWbwGvruUE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transformsL = transforms.Compose([#transforms.Resize(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "valid_transformsL = transforms.Compose([#transforms.Resize(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "test_transformsL = transforms.Compose([#transforms.Resize(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "train_datasetL = ImageFolder('gestos/train', transform=train_transformsL)\n",
        "valid_datasetL = ImageFolder('gestos/valid', transform=valid_transformsL)\n",
        "test_datasetL = ImageFolder('gestos/test', transform=test_transformsL)\n",
        "\n",
        "train_loaderL = DataLoader(train_datasetL, shuffle=True, batch_size=32)\n",
        "valid_loaderL = DataLoader(valid_datasetL, shuffle=False, batch_size=256)\n",
        "test_loaderL = DataLoader(test_datasetL, shuffle=True, batch_size=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kwGWzzdufri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_lenet5(model, criterion, optimizer, num_epochs, best_model):\n",
        "  best_valid_loss = np.inf\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      for x, y in train_loaderL:\n",
        "          x=x.to(device)\n",
        "          y=y.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          yhat = model.forward(x)\n",
        "          loss = criterion(yhat, y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      epoch_loss = 0.0\n",
        "      model.eval()\n",
        "      for x, y in valid_loaderL:\n",
        "          x=x.to(device)\n",
        "          y=y.to(device)\n",
        "          yhat = model.forward(x)\n",
        "          loss = criterion(yhat, y)\n",
        "          epoch_loss += loss.item()\n",
        "      if (epoch_loss < best_valid_loss):\n",
        "        best_valid_loss = epoch_loss\n",
        "        torch.save({'current_epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'current_valid_loss': epoch_loss\n",
        "                   }, best_model)\n",
        "        print(\"guardando..\")\n",
        "      print(epoch, epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pinYE3piujZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testingL(model):\n",
        "  targets, predictions = [], []\n",
        "  for mbdata, label in test_loaderL:\n",
        "      mbdata, label = mbdata.to(device), label.to(device)\n",
        "      logits = model.forward(mbdata)\n",
        "      predictions.append(logits.argmax(dim=1).detach().cpu().numpy())     \n",
        "      targets.append(label.cpu().numpy()) \n",
        "  predictions = np.concatenate(predictions) \n",
        "  targets = np.concatenate(targets)\n",
        "\n",
        "  from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "  cm = confusion_matrix(targets, predictions)\n",
        "  display(cm)\n",
        "  print(classification_report(targets, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUYD75gGupgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "76ef8ff6-6ba8-4a95-b86c-02d6011a8995"
      },
      "source": [
        "import torch\n",
        "\n",
        "class Lenet5(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(type(self), self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(kernel_size = 5, in_channels = 3, out_channels = 6)\n",
        "        self.conv2 = torch.nn.Conv2d(kernel_size = 5, in_channels = 6, out_channels = 16)\n",
        "        self.conv3 = torch.nn.Conv2d(kernel_size = 5, in_channels = 16, out_channels = 32)\n",
        "        self.conv4 = torch.nn.Conv2d(kernel_size = 5, in_channels = 32, out_channels = 64)\n",
        "        self.mpool = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear1 = torch.nn.Linear(in_features=64*8*8,out_features=800)\n",
        "        self.linear2 = torch.nn.Linear(in_features = 800, out_features =400)\n",
        "        self.linear3 = torch.nn.Linear(in_features = 400, out_features =200)\n",
        "        self.linear4 = torch.nn.Linear(in_features = 200, out_features =100)\n",
        "        self.linear5 = torch.nn.Linear(in_features=100,out_features=4)\n",
        "    def forward(self, x):\n",
        "        h = self.mpool(self.activation(self.conv1(x)))\n",
        "        h = self.mpool(self.activation(self.conv2(h)))\n",
        "        h = self.mpool(self.activation(self.conv3(h)))\n",
        "        h = self.mpool(self.activation(self.conv4(h)))\n",
        "        #print(h.shape)\n",
        "        h=h.view(-1, 64*8*8)\n",
        "        h = self.activation(self.linear1(h))\n",
        "        h = self.activation(self.linear2(h))\n",
        "        h = self.activation(self.linear3(h))\n",
        "        h = self.activation(self.linear4(h))\n",
        "\n",
        "\n",
        "        return self.linear5(h)\n",
        "\n",
        "model = Lenet5()\n",
        "display(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Lenet5(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (activation): ReLU()\n",
              "  (linear1): Linear(in_features=4096, out_features=800, bias=True)\n",
              "  (linear2): Linear(in_features=800, out_features=400, bias=True)\n",
              "  (linear3): Linear(in_features=400, out_features=200, bias=True)\n",
              "  (linear4): Linear(in_features=200, out_features=100, bias=True)\n",
              "  (linear5): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA-P0gu_u2WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device)\n",
        "nEpochLeNet5 = 10\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "criterion.to(device) \n",
        "\n",
        "bl = 'best_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgPrx-CXu-Vn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f4d45520-0ed5-49bd-8084-f998f3e7d0a1"
      },
      "source": [
        "train_lenet5(model, criterion, optimizer, nEpochLeNet5, bl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "guardando..\n",
            "0 45.19896803796291\n",
            "1 55.31865841895342\n",
            "2 95.57890623807907\n",
            "3 65.38756975531578\n",
            "4 83.97207576036453\n",
            "5 77.37592155113816\n",
            "6 63.682384757790715\n",
            "7 167.3541099005961\n",
            "8 45.877446696627885\n",
            "9 123.5543510497555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WpdiKoJwBQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "42274eac-68db-49c4-9656-8d79c2e21f75"
      },
      "source": [
        "best_model = Lenet5()\n",
        "\n",
        "best_model.load_state_dict(torch.load('best_model')['model_state_dict'])\n",
        "best_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lenet5(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (activation): ReLU()\n",
              "  (linear1): Linear(in_features=4096, out_features=800, bias=True)\n",
              "  (linear2): Linear(in_features=800, out_features=400, bias=True)\n",
              "  (linear3): Linear(in_features=400, out_features=200, bias=True)\n",
              "  (linear4): Linear(in_features=200, out_features=100, bias=True)\n",
              "  (linear5): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXfpWr8C-TJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "7f50d9bc-601b-4163-d2d6-23ebed39cec7"
      },
      "source": [
        "testingL(best_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 3, 18,  5,  4],\n",
              "       [ 0, 29,  1,  0],\n",
              "       [ 0, 18,  7,  5],\n",
              "       [ 0, 16,  8,  6]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.10      0.18        30\n",
            "           1       0.36      0.97      0.52        30\n",
            "           2       0.33      0.23      0.27        30\n",
            "           3       0.40      0.20      0.27        30\n",
            "\n",
            "    accuracy                           0.38       120\n",
            "   macro avg       0.52      0.38      0.31       120\n",
            "weighted avg       0.52      0.38      0.31       120\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsHanwKitxE9",
        "colab_type": "text"
      },
      "source": [
        "# **Comparación resnet18 vs lenet5 modificada**\n",
        "\n",
        "En la comparación entre estos dos modelos, claramente el nesnet18 es muy superior considerando que es un modelo preentrenado y el lenet5 no. La arquitectura es mas compleja y provada en el resnet 18 y esto lo hace tener mejores resultados.\n",
        "\n",
        "- En cuanto a **precisión** resnet tiene valores (0.98, 1.0, 0.89, 0.82) para las diferentes clases, lo cuál nos muestra valores casi perfectos en comparación con la lenet5  (1.0, 0.36, 0.33, 0.40) que sola la primera clase tiene un buen valor y las demas bordean el 38% de precision.\n",
        "\n",
        "- En cuanto al **recall**, la resnet18 sigue con numeros en porcentaje bastante alto. En cambio la lenet5 (0.1, 0.97, 0.23, 0.20) tenemos valores bastate malos como por ejemplo en la primera clase (0.1), lo cual no sa indicio de que el modelo no es lo sufuciente mente robusto para resolver el problema.\n",
        "\n",
        "- Para la métrica **f1-score**, tenemos valores en torno a 0.90 en la resnet18 para todas las clases. Para lenet5, seguimos viendo peores números que rondan los 0.3\n",
        "\n",
        "Hay que tener en cuenta que el modelo que creamos estaba sobre-entrenado, ya que al ver los valores de la loss en cada época nunca bajo más después de la primera época, también hicimos la prueba de \"testear\" el conjunto de entrenamiento, para el que obtuvimos resultados muy buenos lo cual no era consistente con los resultados obtenidos con el conjunto de \"test\", intentamos aplicar aumentación de datos, pero no logramos evitar el sobre ajuste y menos aún mejorar los resultados.\n",
        "\n",
        "En conclución como se esperaba, la resnet18 pre-entrenada fue muy superior a la lenet5 modificada, considerando obviamente la complejidad de las dos arquitecturas. \n",
        "\n"
      ]
    }
  ]
}